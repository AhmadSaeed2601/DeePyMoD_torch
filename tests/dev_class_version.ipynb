{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from deepymod_torch.library_functions import library_1D\n",
    "from deepymod_torch.DeepMod import DeepMod\n",
    "from deepymod_torch.sparsity import scaling, threshold\n",
    "from deepymod_torch.utilities import create_deriv_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-notebook')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor')  # enable for gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/keller_segel.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.transpose((data['t'].flatten(), data['x'].flatten()))\n",
    "y = np.real(data['u']).reshape((data['u'].size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 500\n",
    "\n",
    "idx = np.random.permutation(y.size)\n",
    "X_train = create_deriv_data(torch.tensor(X[idx, :][:number_of_samples], dtype=torch.float32, requires_grad=True), 3)\n",
    "y_train = torch.tensor(y[idx, :][:number_of_samples], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'input_dim': 2, 'hidden_dim': 20, 'layers': 5, 'output_dim': 1, 'library_function': library_1D, 'library_args':{'poly_order': 2, 'diff_order': 3}}\n",
    "model = DeepMod(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.train(X_train, y_train, optimizer, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |\n",
      "        500    100.00%               0s   1.49e-04   1.49e-04   0.00e+00   0.00e+00 CPU times: user 9.23 s, sys: 5.95 s, total: 15.2 s\n",
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.train(X_train, y_train, optimizer, 500, type='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 8: lda should be at least max(1, 0), but have 0 at ../aten/src/TH/generic/THBlas.cpp:363",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/home/working/src/deepymod_torch/DeepMod.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, target, optimizer, max_iterations, type, loss_func_args)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'deepmod'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mtrain_deepmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/working/src/deepymod_torch/training.py\u001b[0m in \u001b[0;36mtrain_deepmod\u001b[0;34m(data, target, model, optimizer, max_iterations, loss_func_args)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_deepmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# Train first cycle and get prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_deriv_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_theta_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeff_vector_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/working/src/deepymod_torch/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data, target, model, optimizer, max_iterations, loss_func_args)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Calculating loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_deriv_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_theta_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeff_vector_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mloss_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss_l1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoeff_vector_scaled_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/working/src/deepymod_torch/losses.py\u001b[0m in \u001b[0;36mreg_loss\u001b[0;34m(time_deriv_list, sparse_theta_list, coeff_vector_list)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreg_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_deriv_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_theta_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeff_vector_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_deriv\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mcoeff_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtime_deriv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeff_vector\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_deriv_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_theta_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeff_vector_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/working/src/deepymod_torch/losses.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreg_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_deriv_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_theta_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeff_vector_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_deriv\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mcoeff_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtime_deriv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeff_vector\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_deriv_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_theta_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeff_vector_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 8: lda should be at least max(1, 0), but have 0 at ../aten/src/TH/generic/THBlas.cpp:363"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.train(X_train, y_train, optimizer, 100, type='deepmod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([], dtype=torch.int64)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sparsity_mask_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([], size=(0, 1), requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coeff_vector_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing library for higher input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffusion, tests 2D input\n",
    "\n",
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# DeepMoD stuff\n",
    "from deepymod_torch.DeepMod import DeepMod\n",
    "from deepymod_torch.library_functions import library_1D\n",
    "from deepymod_torch.utilities import create_deriv_data\n",
    "\n",
    "# Setting cuda\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "# Settings for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data = np.load('datasets/diffusion_2D.npy', allow_pickle=True).item()\n",
    "X = np.transpose((data['t'].flatten(), data['x'].flatten(), data['y'].flatten()))\n",
    "y = np.real(data['u']).reshape((data['u'].size, 1))\n",
    "number_of_samples = 1000\n",
    "\n",
    "idx = np.random.permutation(y.size)\n",
    "X_train = torch.tensor(X[idx, :][:number_of_samples], dtype=torch.float32, requires_grad=True)\n",
    "y_train = torch.tensor(y[idx, :][:number_of_samples], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running DeepMoD\n",
    "config = {'input_dim': 3, 'hidden_dim': 20, 'layers': 5, 'output_dim': 1, 'library_function': library_1D, 'library_args':{'poly_order': 1, 'diff_order': 2}}\n",
    "\n",
    "X_input = create_deriv_data(X_train, config['library_args']['diff_order'])\n",
    "\n",
    "model = DeepMod(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "du = model(X_input)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2, 3, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "du.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = du[:, :, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0035, -0.0006], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx[0, :, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0035],\n",
       "         [ 0.0006],\n",
       "         [-0.0006],\n",
       "         [-0.0002]]], grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx[0:1, :, :, :].reshape(1, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 4])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx[:, :, :, 0].reshape(dx.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "model.train(X_input, y_train, optimizer, 500, type='deepmod')\n",
    "\n",
    "print(model.sparsity_mask_list, model.coeff_vector_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implementing keller segel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keller Segel, tests coupled output.\n",
    "\n",
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# DeepMoD stuff\n",
    "from deepymod_torch.DeepMod import DeepMod\n",
    "from deepymod_torch.library_functions import library_basic\n",
    "from deepymod_torch.utilities import create_deriv_data\n",
    "\n",
    "# Setting cuda\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "# Settings for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data = np.load('data/keller_segel.npy', allow_pickle=True).item()\n",
    "X = np.transpose((data['t'].flatten(), data['x'].flatten()))\n",
    "y = np.transpose((data['u'].flatten(), data['v'].flatten()))\n",
    "number_of_samples = 1000\n",
    "\n",
    "idx = np.random.permutation(y.shape[0])\n",
    "X_train = torch.tensor(X[idx, :][:number_of_samples], dtype=torch.float32)\n",
    "y_train = torch.tensor(y[idx, :][:number_of_samples], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running DeepMoD\n",
    "config = {'input_dim': 2, 'hidden_dim': 20, 'layers': 5, 'output_dim': 2, 'library_function': library_basic, 'library_args':{'poly_order': 2, 'diff_order': 2}}\n",
    "\n",
    "X_input = create_deriv_data(X_train, config['library_args']['diff_order'])\n",
    "\n",
    "model = DeepMod(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/burgers.npy', allow_pickle=True).item()\n",
    "X = np.transpose((data['t'].flatten(), data['x'].flatten()))\n",
    "y = np.real(data['u']).reshape((data['u'].size, 1))\n",
    "number_of_samples = 1000\n",
    "\n",
    "idx = np.random.permutation(y.size)\n",
    "X_train = torch.tensor(X[idx, :][:number_of_samples], dtype=torch.float32)\n",
    "y_train = torch.tensor(y[idx, :][:number_of_samples], dtype=torch.float32)\n",
    "\n",
    "## Running DeepMoD\n",
    "config = {'input_dim': 2, 'hidden_dim': 20, 'layers': 5, 'output_dim': 1, 'library_function': library_basic, 'library_args':{'poly_order': 2, 'diff_order': 2}}\n",
    "\n",
    "X_input = create_deriv_data(X_train, config['library_args']['diff_order'])\n",
    "\n",
    "model = DeepMod(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(X_input)[0]\n",
    "X, dX = output\n",
    "poly_order = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time deriv shit\n",
    "dt = dX[:, 0, :1, :]\n",
    "time_deriv_list = torch.unbind(dt, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial shit\n",
    "u = torch.ones_like(X)[:, None, :]\n",
    "for order in torch.arange(1, poly_order+1):\n",
    "    u = torch.cat((u, u[:, order-1:order, :] * X[:, None, :]), dim=1)\n",
    "poly_list = torch.unbind(u, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 3])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = dX[:, :, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "deriv_list = [torch.cat((torch.ones((dx.shape[0], 1)), eq.reshape(dx.shape[0], -1)), dim=1) for eq in torch.unbind(dx, dim=3)]\n",
    "samples = dx.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(poly_list) == 1:\n",
    "    theta = torch.matmul(poly_list[0][:, :, None], deriv_list[0][:, None, :]).reshape(samples, -1) # If we have a single output, we simply calculate and flatten matrix product between polynomials and derivatives to get library\n",
    "else:\n",
    "    theta_uv = torch.cat([torch.matmul(u[:, :, None], v[:, None, :]).reshape(samples, -1) for u, v in combinations(poly_list, 2)], 1)  # calculate all unique combinations between polynomials\n",
    "    theta_dudv = torch.cat([torch.matmul(du[:, :, None], dv[:, None, :]).reshape(samples, -1)[:, 1:] for du, dv in combinations(deriv_list, 2)], 1) # calculate all unique combinations of derivatives\n",
    "    theta_udu = torch.cat([torch.matmul(u[:, 1:, None], du[:, None, 1:]).reshape(samples, -1) for u, du in product(poly_list, deriv_list)], 1)  # calculate all unique products of polynomials and derivatives\n",
    "    theta = torch.cat([theta_uv, theta_dudv, theta_udu], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 9])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(theta[:, 0] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(theta[:, 2], dX[:, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(theta[:, 6:7], X**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_deriv_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
