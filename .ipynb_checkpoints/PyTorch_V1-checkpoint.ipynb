{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, torch.nn\n",
    "from library_function import library_1D_new\n",
    "from neural_net import LinNetwork\n",
    "from DeepMod import DeepMod\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-notebook')\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(34) \n",
    "number_of_samples = 1000\n",
    "\n",
    "data = np.load('data/burgers.npy', allow_pickle=True).item()\n",
    "\n",
    "X = np.transpose((data['x'].flatten(), data['t'].flatten()))\n",
    "y = np.real(data['u']).reshape((data['u'].size, 1))\n",
    "\n",
    "idx = np.random.permutation(y.size)\n",
    "X_train = torch.tensor(X[idx, :][:number_of_samples], dtype=torch.float32, requires_grad=True)\n",
    "y_train = torch.tensor(y[idx, :][:number_of_samples], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = LinNetwork(input_dim=2, hidden_dim=20, layers=5, output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_vector = torch.ones(6, 1, dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([{'params':network.parameters()}, {'params': weight_vector}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()    \n",
    "prediction = network(X_train)\n",
    "y = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(3.7311e-06, grad_fn=<AddBackward0>) tensor(-0.1818, grad_fn=<SubBackward0>)\n",
      "100 tensor(3.6724e-06, grad_fn=<AddBackward0>) tensor(-7.3358e-05, grad_fn=<SubBackward0>)\n",
      "200 tensor(3.6312e-06, grad_fn=<AddBackward0>) tensor(-4.9606e-05, grad_fn=<SubBackward0>)\n",
      "300 tensor(3.8892e-06, grad_fn=<AddBackward0>) tensor(9.5919e-05, grad_fn=<SubBackward0>)\n",
      "400 tensor(3.5963e-06, grad_fn=<AddBackward0>) tensor(-0.0001, grad_fn=<SubBackward0>)\n",
      "500 tensor(5.3377e-06, grad_fn=<AddBackward0>) tensor(-4.4078e-05, grad_fn=<SubBackward0>)\n",
      "600 tensor(5.0081e-06, grad_fn=<AddBackward0>) tensor(7.3165e-05, grad_fn=<SubBackward0>)\n",
      "700 tensor(3.8246e-06, grad_fn=<AddBackward0>) tensor(-0.0001, grad_fn=<SubBackward0>)\n",
      "800 tensor(3.4980e-06, grad_fn=<AddBackward0>) tensor(1.9535e-05, grad_fn=<SubBackward0>)\n",
      "900 tensor(3.4562e-06, grad_fn=<AddBackward0>) tensor(-5.7116e-05, grad_fn=<SubBackward0>)\n",
      "1000 tensor(3.4937e-06, grad_fn=<AddBackward0>) tensor(6.1989e-05, grad_fn=<SubBackward0>)\n",
      "1100 tensor(3.4262e-06, grad_fn=<AddBackward0>) tensor(-8.2478e-05, grad_fn=<SubBackward0>)\n",
      "1200 tensor(3.3935e-06, grad_fn=<AddBackward0>) tensor(-4.1530e-05, grad_fn=<SubBackward0>)\n",
      "1300 tensor(3.4495e-06, grad_fn=<AddBackward0>) tensor(6.9141e-05, grad_fn=<SubBackward0>)\n",
      "1400 tensor(3.3593e-06, grad_fn=<AddBackward0>) tensor(-6.8262e-05, grad_fn=<SubBackward0>)\n",
      "1500 tensor(3.3252e-06, grad_fn=<AddBackward0>) tensor(-3.8326e-05, grad_fn=<SubBackward0>)\n",
      "1600 tensor(3.3909e-06, grad_fn=<AddBackward0>) tensor(4.7579e-05, grad_fn=<SubBackward0>)\n",
      "1700 tensor(3.2960e-06, grad_fn=<AddBackward0>) tensor(-6.7174e-05, grad_fn=<SubBackward0>)\n",
      "1800 tensor(2.3697e-05, grad_fn=<AddBackward0>) tensor(0.0001, grad_fn=<SubBackward0>)\n",
      "1900 tensor(3.2710e-06, grad_fn=<AddBackward0>) tensor(-0.0001, grad_fn=<SubBackward0>)\n",
      "2000 tensor(3.2350e-06, grad_fn=<AddBackward0>) tensor(-4.8399e-05, grad_fn=<SubBackward0>)\n",
      "2100 tensor(9.2293e-06, grad_fn=<AddBackward0>) tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "2200 tensor(3.2151e-06, grad_fn=<AddBackward0>) tensor(-0.0002, grad_fn=<SubBackward0>)\n",
      "2300 tensor(3.1807e-06, grad_fn=<AddBackward0>) tensor(-4.4554e-05, grad_fn=<SubBackward0>)\n",
      "2400 tensor(1.9931e-05, grad_fn=<AddBackward0>) tensor(3.9637e-05, grad_fn=<SubBackward0>)\n",
      "2500 tensor(3.1744e-06, grad_fn=<AddBackward0>) tensor(-1.3441e-05, grad_fn=<SubBackward0>)\n",
      "2600 tensor(3.1370e-06, grad_fn=<AddBackward0>) tensor(-4.9308e-05, grad_fn=<SubBackward0>)\n",
      "2700 tensor(3.1110e-06, grad_fn=<AddBackward0>) tensor(-2.2903e-05, grad_fn=<SubBackward0>)\n",
      "2800 tensor(3.1280e-06, grad_fn=<AddBackward0>) tensor(7.5161e-05, grad_fn=<SubBackward0>)\n",
      "2900 tensor(3.0853e-06, grad_fn=<AddBackward0>) tensor(-6.2227e-05, grad_fn=<SubBackward0>)\n",
      "3000 tensor(3.0578e-06, grad_fn=<AddBackward0>) tensor(-2.6256e-05, grad_fn=<SubBackward0>)\n",
      "3100 tensor(3.1008e-06, grad_fn=<AddBackward0>) tensor(5.0247e-05, grad_fn=<SubBackward0>)\n",
      "3200 tensor(3.0387e-06, grad_fn=<AddBackward0>) tensor(-5.5552e-05, grad_fn=<SubBackward0>)\n",
      "3300 tensor(1.9379e-05, grad_fn=<AddBackward0>) tensor(2.4483e-05, grad_fn=<SubBackward0>)\n",
      "3400 tensor(3.0176e-06, grad_fn=<AddBackward0>) tensor(6.4075e-07, grad_fn=<SubBackward0>)\n",
      "3500 tensor(2.9882e-06, grad_fn=<AddBackward0>) tensor(-4.0457e-05, grad_fn=<SubBackward0>)\n",
      "3600 tensor(4.8089e-06, grad_fn=<AddBackward0>) tensor(9.1687e-05, grad_fn=<SubBackward0>)\n",
      "3700 tensor(2.9691e-06, grad_fn=<AddBackward0>) tensor(-7.2911e-05, grad_fn=<SubBackward0>)\n",
      "3800 tensor(2.9419e-06, grad_fn=<AddBackward0>) tensor(-3.0220e-05, grad_fn=<SubBackward0>)\n",
      "3900 tensor(3.9835e-06, grad_fn=<AddBackward0>) tensor(3.8549e-05, grad_fn=<SubBackward0>)\n",
      "4000 tensor(2.9320e-06, grad_fn=<AddBackward0>) tensor(-2.4557e-05, grad_fn=<SubBackward0>)\n",
      "4100 tensor(2.9056e-06, grad_fn=<AddBackward0>) tensor(-2.4766e-05, grad_fn=<SubBackward0>)\n",
      "4200 tensor(4.1978e-06, grad_fn=<AddBackward0>) tensor(9.8139e-05, grad_fn=<SubBackward0>)\n",
      "4300 tensor(2.8869e-06, grad_fn=<AddBackward0>) tensor(-6.6012e-05, grad_fn=<SubBackward0>)\n",
      "4400 tensor(2.8615e-06, grad_fn=<AddBackward0>) tensor(-2.8625e-05, grad_fn=<SubBackward0>)\n",
      "4500 tensor(3.3687e-06, grad_fn=<AddBackward0>) tensor(2.2247e-05, grad_fn=<SubBackward0>)\n",
      "4600 tensor(2.8442e-06, grad_fn=<AddBackward0>) tensor(-1.1802e-05, grad_fn=<SubBackward0>)\n",
      "4700 tensor(2.8304e-06, grad_fn=<AddBackward0>) tensor(-1.7643e-05, grad_fn=<SubBackward0>)\n",
      "4800 tensor(2.8527e-06, grad_fn=<AddBackward0>) tensor(8.3357e-05, grad_fn=<SubBackward0>)\n",
      "4900 tensor(2.8050e-06, grad_fn=<AddBackward0>) tensor(-5.7667e-05, grad_fn=<SubBackward0>)\n",
      "5000 tensor(2.7875e-06, grad_fn=<AddBackward0>) tensor(-2.6137e-05, grad_fn=<SubBackward0>)\n",
      "5100 tensor(2.7982e-06, grad_fn=<AddBackward0>) tensor(2.2650e-05, grad_fn=<SubBackward0>)\n",
      "5200 tensor(3.0202e-06, grad_fn=<AddBackward0>) tensor(-3.9071e-05, grad_fn=<SubBackward0>)\n",
      "5300 tensor(2.7841e-06, grad_fn=<AddBackward0>) tensor(6.8218e-05, grad_fn=<SubBackward0>)\n",
      "5400 tensor(2.7457e-06, grad_fn=<AddBackward0>) tensor(-7.2166e-05, grad_fn=<SubBackward0>)\n",
      "5500 tensor(1.0309e-05, grad_fn=<AddBackward0>) tensor(-2.2650e-06, grad_fn=<SubBackward0>)\n",
      "5600 tensor(2.7385e-06, grad_fn=<AddBackward0>) tensor(2.8595e-05, grad_fn=<SubBackward0>)\n",
      "5700 tensor(2.7120e-06, grad_fn=<AddBackward0>) tensor(-4.8965e-05, grad_fn=<SubBackward0>)\n",
      "5800 tensor(5.8005e-06, grad_fn=<AddBackward0>) tensor(-0.0002, grad_fn=<SubBackward0>)\n",
      "5900 tensor(2.7059e-06, grad_fn=<AddBackward0>) tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "6000 tensor(2.6830e-06, grad_fn=<AddBackward0>) tensor(-4.0665e-05, grad_fn=<SubBackward0>)\n",
      "6100 tensor(4.3549e-06, grad_fn=<AddBackward0>) tensor(-9.0778e-05, grad_fn=<SubBackward0>)\n",
      "6200 tensor(2.6626e-06, grad_fn=<AddBackward0>) tensor(8.7872e-05, grad_fn=<SubBackward0>)\n",
      "6300 tensor(2.7573e-06, grad_fn=<AddBackward0>) tensor(6.4954e-05, grad_fn=<SubBackward0>)\n",
      "6400 tensor(2.6473e-06, grad_fn=<AddBackward0>) tensor(-6.1795e-05, grad_fn=<SubBackward0>)\n",
      "6500 tensor(1.1358e-05, grad_fn=<AddBackward0>) tensor(-0.0003, grad_fn=<SubBackward0>)\n",
      "6600 tensor(2.6398e-06, grad_fn=<AddBackward0>) tensor(0.0003, grad_fn=<SubBackward0>)\n",
      "6700 tensor(2.6210e-06, grad_fn=<AddBackward0>) tensor(-2.6017e-05, grad_fn=<SubBackward0>)\n",
      "6800 tensor(3.0068e-06, grad_fn=<AddBackward0>) tensor(6.2495e-05, grad_fn=<SubBackward0>)\n",
      "6900 tensor(2.6101e-06, grad_fn=<AddBackward0>) tensor(-6.8158e-05, grad_fn=<SubBackward0>)\n",
      "7000 tensor(4.2694e-06, grad_fn=<AddBackward0>) tensor(-0.0001, grad_fn=<SubBackward0>)\n",
      "7100 tensor(2.8782e-06, grad_fn=<AddBackward0>) tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "7200 tensor(2.6215e-06, grad_fn=<AddBackward0>) tensor(-1.6689e-05, grad_fn=<SubBackward0>)\n",
      "7300 tensor(2.5803e-06, grad_fn=<AddBackward0>) tensor(-5.3614e-05, grad_fn=<SubBackward0>)\n",
      "7400 tensor(2.6122e-06, grad_fn=<AddBackward0>) tensor(3.4973e-05, grad_fn=<SubBackward0>)\n",
      "7500 tensor(2.5636e-06, grad_fn=<AddBackward0>) tensor(-6.4358e-05, grad_fn=<SubBackward0>)\n",
      "7600 tensor(2.5875e-06, grad_fn=<AddBackward0>) tensor(4.0919e-05, grad_fn=<SubBackward0>)\n",
      "7700 tensor(2.5568e-06, grad_fn=<AddBackward0>) tensor(-5.8919e-05, grad_fn=<SubBackward0>)\n",
      "7800 tensor(5.3939e-06, grad_fn=<AddBackward0>) tensor(-0.0002, grad_fn=<SubBackward0>)\n",
      "7900 tensor(2.5471e-06, grad_fn=<AddBackward0>) tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "8000 tensor(2.5332e-06, grad_fn=<AddBackward0>) tensor(-3.0413e-05, grad_fn=<SubBackward0>)\n",
      "8100 tensor(2.5644e-06, grad_fn=<AddBackward0>) tensor(6.4805e-05, grad_fn=<SubBackward0>)\n",
      "8200 tensor(2.5314e-06, grad_fn=<AddBackward0>) tensor(-7.6413e-05, grad_fn=<SubBackward0>)\n",
      "8300 tensor(2.5180e-06, grad_fn=<AddBackward0>) tensor(-1.8880e-05, grad_fn=<SubBackward0>)\n",
      "8400 tensor(2.5951e-06, grad_fn=<AddBackward0>) tensor(9.0465e-05, grad_fn=<SubBackward0>)\n",
      "8500 tensor(2.5153e-06, grad_fn=<AddBackward0>) tensor(-7.1764e-05, grad_fn=<SubBackward0>)\n",
      "8600 tensor(2.5032e-06, grad_fn=<AddBackward0>) tensor(-2.1592e-05, grad_fn=<SubBackward0>)\n",
      "8700 tensor(3.1537e-06, grad_fn=<AddBackward0>) tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "8800 tensor(2.5065e-06, grad_fn=<AddBackward0>) tensor(-0.0002, grad_fn=<SubBackward0>)\n",
      "8900 tensor(2.4933e-06, grad_fn=<AddBackward0>) tensor(-2.3946e-05, grad_fn=<SubBackward0>)\n",
      "9000 tensor(5.0203e-06, grad_fn=<AddBackward0>) tensor(-1.9088e-05, grad_fn=<SubBackward0>)\n",
      "9100 tensor(2.5003e-06, grad_fn=<AddBackward0>) tensor(3.3617e-05, grad_fn=<SubBackward0>)\n",
      "9200 tensor(2.4816e-06, grad_fn=<AddBackward0>) tensor(-3.6657e-05, grad_fn=<SubBackward0>)\n",
      "9300 tensor(0.0001, grad_fn=<AddBackward0>) tensor(-4.0799e-05, grad_fn=<SubBackward0>)\n",
      "9400 tensor(2.4813e-06, grad_fn=<AddBackward0>) tensor(7.7516e-05, grad_fn=<SubBackward0>)\n",
      "9500 tensor(2.4662e-06, grad_fn=<AddBackward0>) tensor(-4.0948e-05, grad_fn=<SubBackward0>)\n",
      "9600 tensor(1.8595e-05, grad_fn=<AddBackward0>) tensor(-0.0002, grad_fn=<SubBackward0>)\n",
      "9700 tensor(2.4644e-06, grad_fn=<AddBackward0>) tensor(0.0002, grad_fn=<SubBackward0>)\n",
      "9800 tensor(2.4534e-06, grad_fn=<AddBackward0>) tensor(-1.6689e-05, grad_fn=<SubBackward0>)\n",
      "9900 tensor(2.4885e-06, grad_fn=<AddBackward0>) tensor(7.0810e-05, grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "l1=10**(-5)\n",
    "loss_L1_pre =  l1*loss_L1(weight_vector,torch.zeros_like(weight_vector))\n",
    "for iteration in np.arange(10000):\n",
    "    optimizer.zero_grad()    \n",
    "    prediction = network(X_train)\n",
    "    y = prediction\n",
    "    y_t, theta = library_1D_new(X_train, y,library_config={'poly_order':1,'diff_order':2})\n",
    "    f = y_t - theta @ weight_vector\n",
    "    loss_PI = torch.nn.MSELoss()\n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = nn.L1Loss()\n",
    "    loss = loss_MSE(prediction, y_train) + loss_PI(f, torch.zeros_like(f)) + l1*loss_L1(weight_vector,torch.zeros_like(weight_vector))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if iteration % 100 == 0:\n",
    "        print(iteration, loss, loss_L1_pre -  loss_L1(weight_vector,torch.zeros_like(weight_vector)))\n",
    "        loss_L1_pre =  loss_L1(weight_vector,torch.zeros_like(weight_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_time = torch.norm(y_t).detach().numpy()\n",
    "scaled_theta = torch.norm(theta,dim=0).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_weight_vector = np.squeeze(weight_vector.detach().numpy())*scaled_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.5746e-05],\n",
       "        [-2.1027e-03],\n",
       "        [ 9.9532e-02],\n",
       "        [-5.5832e-04],\n",
       "        [-9.9276e-01],\n",
       "        [-1.1922e-03]], requires_grad=True)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=10, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (5): Tanh()\n",
      "  (6): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (7): Tanh()\n",
      "  (8): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (9): Tanh()\n",
      "  (10): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "DeepMod(X_train, y_train, config={'input_dim':2, 'hidden_dim':10, 'layers':5, 'output_dim':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(0,1000,1).reshape(-1,1)\n",
    "y = X*X.reshape(-1,1)\n",
    "idx = np.random.permutation(y.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X[:, :][:number_of_samples], dtype=torch.float32, requires_grad=True)\n",
    "y_train = torch.tensor(y[:, :][:number_of_samples], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = LinNetwork(input_dim=1, hidden_dim=10, layers=5, output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = network(X_train)\n",
    "y = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.1584, 0.0251],\n",
      "        [1.0000, 0.1471, 0.0217],\n",
      "        [1.0000, 0.1337, 0.0179],\n",
      "        [1.0000, 0.1316, 0.0173],\n",
      "        [1.0000, 0.1339, 0.0179],\n",
      "        [1.0000, 0.1372, 0.0188],\n",
      "        [1.0000, 0.1406, 0.0198],\n",
      "        [1.0000, 0.1437, 0.0207],\n",
      "        [1.0000, 0.1464, 0.0214],\n",
      "        [1.0000, 0.1487, 0.0221]], grad_fn=<CatBackward>)\n",
      "tensor([[ 1.0000e+00, -3.4018e-03, -1.2140e-02],\n",
      "        [ 1.0000e+00, -1.7684e-02, -2.4011e-03],\n",
      "        [ 1.0000e+00, -6.8308e-03,  1.3013e-02],\n",
      "        [ 1.0000e+00,  1.0594e-03,  3.8364e-03],\n",
      "        [ 1.0000e+00,  3.0818e-03,  8.6494e-04],\n",
      "        [ 1.0000e+00,  3.4536e-03,  2.6085e-05],\n",
      "        [ 1.0000e+00,  3.2918e-03, -3.0473e-04],\n",
      "        [ 1.0000e+00,  2.9105e-03, -4.3198e-04],\n",
      "        [ 1.0000e+00,  2.4694e-03, -4.3464e-04],\n",
      "        [ 1.0000e+00,  2.0625e-03, -3.7298e-04]], grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([], size=(10, 0), grad_fn=<SliceBackward>),\n",
       " tensor([[ 1.0000e+00, -3.4018e-03, -1.2140e-02,  1.0000e+00, -3.4018e-03,\n",
       "          -1.2140e-02,  1.5843e-01, -5.3895e-04, -1.9233e-03],\n",
       "         [ 1.0000e+00, -1.7684e-02, -2.4011e-03,  1.0000e+00, -1.7684e-02,\n",
       "          -2.4011e-03,  1.4715e-01, -2.6021e-03, -3.5332e-04],\n",
       "         [ 1.0000e+00, -6.8308e-03,  1.3013e-02,  1.0000e+00, -6.8308e-03,\n",
       "           1.3013e-02,  1.3367e-01, -9.1310e-04,  1.7395e-03],\n",
       "         [ 1.0000e+00,  1.0594e-03,  3.8364e-03,  1.0000e+00,  1.0594e-03,\n",
       "           3.8364e-03,  1.3157e-01,  1.3938e-04,  5.0476e-04],\n",
       "         [ 1.0000e+00,  3.0818e-03,  8.6494e-04,  1.0000e+00,  3.0818e-03,\n",
       "           8.6494e-04,  1.3388e-01,  4.1260e-04,  1.1580e-04],\n",
       "         [ 1.0000e+00,  3.4536e-03,  2.6085e-05,  1.0000e+00,  3.4536e-03,\n",
       "           2.6085e-05,  1.3722e-01,  4.7390e-04,  3.5793e-06],\n",
       "         [ 1.0000e+00,  3.2918e-03, -3.0473e-04,  1.0000e+00,  3.2918e-03,\n",
       "          -3.0473e-04,  1.4062e-01,  4.6289e-04, -4.2850e-05],\n",
       "         [ 1.0000e+00,  2.9105e-03, -4.3198e-04,  1.0000e+00,  2.9105e-03,\n",
       "          -4.3198e-04,  1.4373e-01,  4.1832e-04, -6.2089e-05],\n",
       "         [ 1.0000e+00,  2.4694e-03, -4.3464e-04,  1.0000e+00,  2.4694e-03,\n",
       "          -4.3464e-04,  1.4642e-01,  3.6156e-04, -6.3640e-05],\n",
       "         [ 1.0000e+00,  2.0625e-03, -3.7298e-04,  1.0000e+00,  2.0625e-03,\n",
       "          -3.7298e-04,  1.4868e-01,  3.0665e-04, -5.5455e-05]],\n",
       "        grad_fn=<CatBackward>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library_1D_new(X_train, y,library_config={'poly_order':2,'diff_order':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
